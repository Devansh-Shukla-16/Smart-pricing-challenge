{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devansh-Shukla-16/Smart-pricing-challenge/blob/main/Smart_Product_Pricing_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_aFtYSpaI5zH"
      },
      "outputs": [],
      "source": [
        "!pip install pandas==2.2.2 numpy==1.26.4 pillow==10.3.0 opencv-python==4.10.0.84 \\\n",
        "scikit-learn==1.5.2 tqdm==4.66.5 requests==2.32.3 transformers==4.44.2 tokenizers==0.19.1 torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VW-sfGxiKqwG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models, transforms\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY0_cm1qQoa_"
      },
      "source": [
        "üìÅ Step 3: Load your dataset (adjust paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8jEcBZnK-jP"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "print(train_df.shape, test_df.shape)\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wQNhejvQzCd"
      },
      "source": [
        "üñºÔ∏è Step 4: Define image download helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dMWTLSnLFlA"
      },
      "outputs": [],
      "source": [
        "def download_image(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        return img\n",
        "    except:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVem4R3XLMDN"
      },
      "source": [
        "üî§ Step 5 ‚Äì Text Embeddings (using MiniLM for speed)\n",
        "\n",
        "üß† Step 5: Generate text embeddings (optimized with batching ‚úÖ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmqrsDBCLIpe"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "text_model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "text_model.eval()\n",
        "\n",
        "def get_text_embeddings(texts, batch_size=16):\n",
        "    all_embeddings = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size)):\n",
        "        batch_texts = texts[i:i+batch_size].tolist()\n",
        "        enc = tokenizer(batch_texts, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n",
        "        with torch.no_grad():\n",
        "            out = text_model(**enc).last_hidden_state.mean(dim=1)\n",
        "        all_embeddings.append(out.cpu())\n",
        "    return torch.cat(all_embeddings).numpy()\n",
        "\n",
        "train_text_emb = get_text_embeddings(train_df[\"catalog_content\"][:5000])  # adjust if memory allows\n",
        "test_text_emb  = get_text_embeddings(test_df[\"catalog_content\"][:5000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVzrdjWVMDxu"
      },
      "source": [
        "üñºÔ∏è Step 6 ‚Äì Image Embeddings (using Vision Transformer)\n",
        "\n",
        "üèûÔ∏è Step 6: Generate image embeddings (optimized with batching ‚úÖ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "igRMCNFyLSER"
      },
      "outputs": [],
      "source": [
        "img_model = models.resnet50(pretrained=True)\n",
        "img_model.fc = nn.Identity()\n",
        "img_model = img_model.to(device)\n",
        "img_model.eval()\n",
        "\n",
        "img_preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def get_image_embeddings(df, batch_size=8):\n",
        "    embeddings = []\n",
        "    for i in tqdm(range(len(df))):\n",
        "        img = download_image(df.iloc[i][\"image_link\"])\n",
        "        if img is not None:\n",
        "            img_t = img_preprocess(img).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                emb = img_model(img_t).cpu().numpy()\n",
        "            embeddings.append(emb)\n",
        "        else:\n",
        "            embeddings.append(np.zeros((1, 2048)))\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "train_img_emb = get_image_embeddings(train_df[:5000])\n",
        "test_img_emb  = get_image_embeddings(test_df[:5000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgFMFz1wMKF-"
      },
      "source": [
        "‚ö° Step 7 ‚Äì Combine Features + Train Model\n",
        "\n",
        "üèûÔ∏è Step 7: Chunked image embeddings (saves each batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAGGuUZmMGTs"
      },
      "outputs": [],
      "source": [
        "def generate_image_embeddings(df, name_prefix, batch_size=8, chunk_size=1000):\n",
        "    for start in range(0, len(df), chunk_size):\n",
        "        end = min(start + chunk_size, len(df))\n",
        "        all_emb = []\n",
        "        for i in tqdm(range(start, end), desc=f\"Image {start}-{end}\"):\n",
        "            img = download_image(df.iloc[i][\"image_link\"])\n",
        "            if img is not None:\n",
        "                img_t = img_preprocess(img).unsqueeze(0).to(device)\n",
        "                with torch.no_grad():\n",
        "                    emb = img_model(img_t).cpu().numpy()\n",
        "                all_emb.append(emb)\n",
        "            else:\n",
        "                all_emb.append(np.zeros((1, 2048)))\n",
        "            torch.cuda.empty_cache()\n",
        "        np.save(f\"/content/embeddings/{name_prefix}_{start}_{end}.npy\", np.vstack(all_emb))\n",
        "        del all_emb; gc.collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUVnwS2EMRgF"
      },
      "source": [
        "‚öôÔ∏è Step 8: Generate embeddings for train & test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KikPNziVMQ7b"
      },
      "outputs": [],
      "source": [
        "get_text_embeddings(train_df, \"train_text\")\n",
        "get_text_embeddings(test_df, \"test_text\")\n",
        "generate_image_embeddings(train_df, \"train_img\")\n",
        "generate_image_embeddings(test_df, \"test_img\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYKKn0A1MUft"
      },
      "source": [
        "üßæ Step 9 ‚Äì Generate Test Predictions & CSV\n",
        "\n",
        "üß© Step 9: Merge embeddings from all chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzoQxGREMQ4B"
      },
      "outputs": [],
      "source": [
        "def load_all_embeddings(prefix):\n",
        "    files = sorted([f for f in os.listdir(\"/content/embeddings\") if f.startswith(prefix)])\n",
        "    arrays = [np.load(os.path.join(\"/content/embeddings\", f)) for f in files]\n",
        "    return np.vstack(arrays)\n",
        "\n",
        "train_text_emb = load_all_embeddings(\"train_text\")\n",
        "train_img_emb = load_all_embeddings(\"train_img\")\n",
        "test_text_emb  = load_all_embeddings(\"test_text\")\n",
        "test_img_emb   = load_all_embeddings(\"test_img\")\n",
        "\n",
        "train_features = np.concatenate([train_text_emb, train_img_emb], axis=1)\n",
        "test_features  = np.concatenate([test_text_emb, test_img_emb], axis=1)\n",
        "train_labels = train_df[\"price\"].values[:len(train_features)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvUPH3yCRoec"
      },
      "source": [
        "‚öñÔ∏è Step 10: Train model and normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEF70scWMQzt"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "train_scaled = scaler.fit_transform(train_features)\n",
        "test_scaled = scaler.transform(test_features)\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=250, max_depth=25, n_jobs=-1, random_state=42)\n",
        "model.fit(train_scaled, train_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wrHuOBNRux7"
      },
      "source": [
        "üßæ Step 11: Predict and save output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK-_VVMFRs37"
      },
      "outputs": [],
      "source": [
        "test_preds = model.predict(test_scaled)\n",
        "\n",
        "out = pd.DataFrame({\n",
        "    \"sample_id\": test_df[\"sample_id\"],\n",
        "    \"price\": np.maximum(test_preds, 0)\n",
        "})\n",
        "out.to_csv(\"test_out.csv\", index=False)\n",
        "print(\"‚úÖ test_out.csv generated successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQsJTuUkMP98"
      },
      "source": [
        "üìä Step 12 (Optional): Validate with a small sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-xqP_vVRtxU"
      },
      "outputs": [],
      "source": [
        "val_pred = model.predict(train_scaled[:1000])\n",
        "val_true = train_labels[:1000]\n",
        "smape = np.mean(np.abs(val_pred - val_true) / ((np.abs(val_pred) + np.abs(val_true)) / 2)) * 100\n",
        "print(f\"Validation SMAPE: {smape:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGCGIWMktAB-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMDwzEJWHigrTFoWoLCnQnX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}